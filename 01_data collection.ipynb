{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "We will use a package called `BeautifulSoup` to webscrap and collect the data from the web. The data will then be saved in a local `csv` file for further prprocessing.\n",
    "\n",
    "We will scrap the reviews from [https://www.airlinequality.com], using `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n"
     ]
    }
   ],
   "source": [
    "# We are only interested in reviews for British Airways\n",
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways/\"\n",
    "pages = 20\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "stars = []\n",
    "date = []\n",
    "country = []\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "\n",
    "    # collect all stars\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"rating-10\"}):\n",
    "        try:\n",
    "            stars.append(para.span.get_text())\n",
    "        except:\n",
    "            stars.append(np.nan)\n",
    "\n",
    "    # collect all dates\n",
    "    for para in parsed_content.find_all(\"time\"):\n",
    "        date.append(para.get_text())\n",
    "\n",
    "    # collect country\n",
    "    for para in parsed_content.find_all(\"h3\"):\n",
    "        country.append(para.span.next_sibling.text.strip(\" ()\"))\n",
    "\n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2020\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "# check the length of the lists\n",
    "print(len(reviews))\n",
    "print(len(stars))\n",
    "print(len(date))\n",
    "print(len(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5',\n",
       " '1',\n",
       " '9',\n",
       " '2',\n",
       " '7',\n",
       " '7',\n",
       " '1',\n",
       " '4',\n",
       " '1',\n",
       " '2',\n",
       " '1',\n",
       " '5',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '6',\n",
       " '1',\n",
       " '9',\n",
       " '9',\n",
       " '3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate the stars list\n",
    "stars[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2019 2000 2000\n",
      "2000 2000 2000 2000\n"
     ]
    }
   ],
   "source": [
    "# remove first entry of stars\n",
    "stars = stars[1:]\n",
    "\n",
    "# check if all lists have the same length\n",
    "print(len(reviews), len(stars), len(date), len(country))\n",
    "\n",
    "# make length of stars equal to reviews\n",
    "stars = stars[:len(reviews)]\n",
    "\n",
    "# check again\n",
    "print(len(reviews), len(stars), len(date), len(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  I was flying to Warsaw for ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Booked a BA holiday to Marr...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Extremely sub-par service. H...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  I virtually gave up on Brit...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-11-26</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  I was pleasantly surprised ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  stars       date  \\\n",
       "0  ✅ Trip Verified |  I was flying to Warsaw for ...    1.0 2022-12-03   \n",
       "1  ✅ Trip Verified |  Booked a BA holiday to Marr...    9.0 2022-11-30   \n",
       "2  ✅ Trip Verified | Extremely sub-par service. H...    2.0 2022-11-28   \n",
       "3  ✅ Trip Verified |  I virtually gave up on Brit...    7.0 2022-11-26   \n",
       "4  ✅ Trip Verified |  I was pleasantly surprised ...    7.0 2022-11-25   \n",
       "\n",
       "          country  \n",
       "0   United States  \n",
       "1  United Kingdom  \n",
       "2   United States  \n",
       "3  United Kingdom  \n",
       "4          Canada  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list of (review, stars, date, country) tuples\n",
    "data = list(zip(reviews, stars, date, country))\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(data, columns=[\"review\", \"stars\", \"date\", \"country\"])\n",
    "\n",
    "# convert date to datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# convert stars to float\n",
    "df[\"stars\"] = df[\"stars\"].astype(float)\n",
    "\n",
    "# see first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected about 2000 reviews by iterating through the paginated pages on the website. To increase the number of data collected, we just have to increase the page count. In the next step, we will do cleaning on the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc902f5f9f1b4ac8244fa2d1a71d10e1bb8b95bd909217946ac119cb82bcf206"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
